{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Decision tree clasifier\n",
    "\"\"\"\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node is the clas that represents one leave of the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gini, feature_index, threshold, left, right, combined_data):\n",
    "        self.gini = gini\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.combined_data = combined_data\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.threshold}\"\n",
    "\n",
    "\n",
    "# Implement a decision tree classifier\n",
    "class MyDecisionTreeClassifier:\n",
    "    \"\"\"\n",
    "    Class of the tree that\n",
    "    1) Has gini index function\n",
    "    2) Has split data function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.treeee = object\n",
    "\n",
    "    def gini(self, groups):\n",
    "        \"\"\"\n",
    "        A Gini score gives an idea of how good a split is by how mixed the\n",
    "        classes are in the two groups created by the split.\n",
    "\n",
    "        A perfect separation results in a Gini score of 0,\n",
    "        whereas the worst case split that results in 50/50\n",
    "        classes in each group result in a Gini score of 0.5\n",
    "        (for a 2 class problem).\n",
    "        \"\"\"\n",
    "        all_types = {}\n",
    "        gini = 1\n",
    "        for elem in groups:\n",
    "            if elem[1] not in all_types:\n",
    "                all_types[elem[1]] = 1\n",
    "            else:\n",
    "                all_types[elem[1]] += 1\n",
    "        for item in all_types.values():\n",
    "            gini -= (int(item) / len(groups)) ** 2\n",
    "        return gini\n",
    "\n",
    "    def split_data(self, combined_data) -> tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Function that finds the best question to\n",
    "        split the tree and get as much unformation as possible.\n",
    "        \"\"\"\n",
    "        # test all the possible splits in O(N*F) where N in number of samples\n",
    "        # and F is number of features\n",
    "\n",
    "        # return index and threshold value\n",
    "\n",
    "        max_gain_index = 0\n",
    "        basic_impurity = self.gini(combined_data)\n",
    "        true_impurity = 0\n",
    "        false_impurity = 0\n",
    "        avg_impurity = 0\n",
    "        feature_index = 0\n",
    "        feature_value = 0\n",
    "        for i, _ in enumerate(combined_data):\n",
    "            for j, _ in enumerate(combined_data[0][0]):\n",
    "                true_list = []\n",
    "                false_list = []\n",
    "                for elem in combined_data:\n",
    "                    if elem[0][j] > combined_data[i][0][j]:\n",
    "                        true_list.append(elem)\n",
    "                    else:\n",
    "                        false_list.append(elem)\n",
    "\n",
    "                true_impurity = self.gini(true_list)\n",
    "                false_impurity = self.gini(false_list)\n",
    "                avg_impurity = (\n",
    "                    len(true_list) / len(combined_data)\n",
    "                ) * true_impurity + false_impurity * (\n",
    "                    len(false_list) / len(combined_data)\n",
    "                )\n",
    "                if max_gain_index < basic_impurity - avg_impurity:\n",
    "                    max_gain_index = basic_impurity - avg_impurity\n",
    "                    feature_index = j\n",
    "                    feature_value = combined_data[i][0][j]\n",
    "        return (max_gain_index, feature_index, feature_value)\n",
    "\n",
    "    def build_tree(self, combined_data, depth=0):\n",
    "        \"\"\"\n",
    "        Builds Tree\n",
    "        \"\"\"\n",
    "        max_gain_index, feature_index, feature_value = self.split_data(combined_data)\n",
    "        if depth < self.max_depth and max_gain_index != 0:\n",
    "            true_list = []\n",
    "            false_list = []\n",
    "            for elem in combined_data:\n",
    "                if elem[0][feature_index] > feature_value:\n",
    "                    true_list.append(elem)\n",
    "                else:\n",
    "                    false_list.append(elem)\n",
    "            left_tree = self.build_tree(true_list, depth=depth + 1)\n",
    "            right_tree = self.build_tree(false_list, depth=depth + 1)\n",
    "            return Node(\n",
    "                max_gain_index,\n",
    "                feature_index,\n",
    "                feature_value,\n",
    "                left_tree,\n",
    "                right_tree,\n",
    "                combined_data,\n",
    "            )\n",
    "        return Node(max_gain_index, 0, 0, 0, 0, combined_data)\n",
    "\n",
    "    def fit(self, x_list, y_list):\n",
    "        \"\"\"\n",
    "        Function that train tree with data\n",
    "        \"\"\"\n",
    "        self.treeee = self.build_tree(list(zip(x_list, y_list)))\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Evaluate accuracy\n",
    "        \"\"\"\n",
    "        predictions_list = []\n",
    "        for test in x_test:\n",
    "            current_node = self.treeee\n",
    "            leaves_data = []\n",
    "            possibility_dict = {}\n",
    "            while True:\n",
    "                if test[current_node.feature_index] > current_node.threshold:\n",
    "                    current_node = current_node.left\n",
    "                else:\n",
    "                    current_node = current_node.right\n",
    "                if not current_node.right and not current_node.left:\n",
    "                    break\n",
    "            leaves_data = current_node.combined_data\n",
    "            for data in leaves_data:\n",
    "                if data[1] in possibility_dict:\n",
    "                    possibility_dict[data[1]] += 1\n",
    "                else:\n",
    "                    possibility_dict[data[1]] = 1\n",
    "            predictions_list.append(max(possibility_dict))\n",
    "        return predictions_list\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate accuracy\n",
    "        \"\"\"\n",
    "        return sum(self.predict(x_test) == y_test) / len(y_test)\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "treeee = MyDecisionTreeClassifier(10)\n",
    "treeee.fit(x_test, y_test)\n",
    "print(treeee.evaluate(x,y))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3cd7ac9b68df26e0ca816e833eb9f1d0adb0e9b3c3f1b9cdfae1c5725931d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
